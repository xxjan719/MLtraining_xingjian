{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282ec347",
   "metadata": {},
   "source": [
    "# Assignment for Topic 2: Logistic Regression\n",
    "\n",
    "\n",
    "Hi,there! This assignment is created by @Xingjian and checked by Professor @Jiahui and @Chunmei.\n",
    "\n",
    "\n",
    "## Another Edition\n",
    "\n",
    "This is an edition for jupyter notebook. About .py edition, please see attachment in this folder.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "In this section, I choose the dataset from Kaggle, here is link: [Diabetes Healthcare: Comprehensive Dataset-AI](https://www.kaggle.com/datasets/deependraverma13/diabetes-healthcare-comprehensive-dataset?resource=download).You can download it and check all the details about this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3814efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"D:\\\\MLtraining_xingjian\\\\2_logistic_regression\\\\Train2\\\\health_care_diabetes.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1737f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "5            5      116             74              0        0  25.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  \n",
       "5                     0.201   30        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a917822",
   "metadata": {},
   "source": [
    "Then we can use the normalization to clean the data (but not including outcome) as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd5e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.84832379  0.14964075 ...  0.46849198  1.4259954\n",
      "   1.36589591]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.36506078 -0.19067191\n",
      "  -0.73212021]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ...  0.60439732 -0.10558415\n",
      "   1.36589591]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ... -0.68519336 -0.27575966\n",
      "  -0.73212021]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.37110101  1.17073215\n",
      "   1.36589591]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.47378505 -0.87137393\n",
      "  -0.73212021]]\n",
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mm = StandardScaler() #create the object for normalization\n",
    "dd = np.array(data)\n",
    "mm_data = mm.fit_transform(dd)\n",
    "print(mm_data)\n",
    "origin_data = mm.inverse_transform(mm_data) # return back to original data\n",
    "print(origin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b8949",
   "metadata": {},
   "source": [
    "## Define the Logistic Sigmoid Function $\\sigma(z)$\n",
    "\n",
    "we know Logistic Sigmoid Function is as following:\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8d525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c19fa",
   "metadata": {},
   "source": [
    "And we can check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907d1eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a82ac",
   "metadata": {},
   "source": [
    "## Define LogisticRegression\n",
    "\n",
    "Then we can give the class object of LogisticRegression like following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb461e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression2:\n",
    "    def __init__(self, M, N, lr=0.1):\n",
    "        # unlike linear regression. we need the weight matrix here\n",
    "        # StandardScaler(): normalizer, which is important\n",
    "        # initailize all variables\n",
    "        self.W = np.random.normal(0,1,size=(N,1))# weight matrix\n",
    "        self.b = np.random.rand(1).reshape(1,1)# bias\n",
    "        self.lr = lr\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "    def fit(self, X, y, epoch=5000):\n",
    "        # normalize first\n",
    "        # for each epoch, update the weight matrix and bias\n",
    "        M,N = np.shape(X)\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(y.shape[0],1)\n",
    "            \n",
    "        weights = np.concatenate([self.b, self.W],axis=0)\n",
    "        X = np.c_[np.ones((np.shape(X)[0],1)),X]\n",
    "        costs = []\n",
    "        \n",
    "        for i in range(1,epoch+1):\n",
    "            H = sigmoid(np.dot(X,weights))        \n",
    "            cost0 = y.T.dot(np.log(sigmoid(H)))\n",
    "            cost1 = (1-y).T.dot(np.log(1-sigmoid(H)))\n",
    "            cost = -((cost1 + cost0))/self.M\n",
    "            cost = np.squeeze(cost)\n",
    "            costs.append(cost)\n",
    "            weights = weights - self.lr * np.dot(X.T, sigmoid(np.dot(X,weights)) - np.reshape(y,(len(y),1)))\n",
    "            if i % 100 == 0:\n",
    "                print ('Epoch:{}, The cost is :{}'.format(i, cost))\n",
    "        \n",
    "        self.b = weights[0]\n",
    "        \n",
    "        self.W = weights[1:]\n",
    "        \n",
    "        return self.W, self.b, costs\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X = np.c_[np.ones((np.shape(X_test)[0],1)),X_test]\n",
    "        weight = np.concatenate([self.b.reshape(self.b.shape[0],1), self.W.reshape(self.W.shape[0],1)],axis=0)\n",
    "        H = sigmoid(np.dot(X,weight))\n",
    "        y_pred = []\n",
    "        for i in H:\n",
    "            if i>0.5:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c70ca",
   "metadata": {},
   "source": [
    "But we also need some measurement to verify this performance, we will use $F_{1}$ score to finish this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7feb9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y,y_hat):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and y_hat[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 1 and y_hat[i] == 0:\n",
    "            fn += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 1:\n",
    "            fp += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 0:\n",
    "            tn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbe3ca",
   "metadata": {},
   "source": [
    "Now we can check like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d08cf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, The cost is :0.6998769095082942\n",
      "Epoch:200, The cost is :0.6998769095082942\n",
      "Epoch:300, The cost is :0.6998769095082942\n",
      "Epoch:400, The cost is :0.6998769095082942\n",
      "Epoch:500, The cost is :0.6998769095082942\n",
      "Epoch:600, The cost is :0.6998769095082942\n",
      "Epoch:700, The cost is :0.6998769095082942\n",
      "Epoch:800, The cost is :0.6998769095082942\n",
      "Epoch:900, The cost is :0.6998769095082942\n",
      "Epoch:1000, The cost is :0.6998769095082942\n",
      "Epoch:1100, The cost is :0.6998769095082942\n",
      "Epoch:1200, The cost is :0.6998769095082942\n",
      "Epoch:1300, The cost is :0.6998769095082942\n",
      "Epoch:1400, The cost is :0.6998769095082942\n",
      "Epoch:1500, The cost is :0.6998769095082942\n",
      "Epoch:1600, The cost is :0.6998769095082942\n",
      "Epoch:1700, The cost is :0.6998769095082942\n",
      "Epoch:1800, The cost is :0.6998769095082942\n",
      "Epoch:1900, The cost is :0.6998769095082942\n",
      "Epoch:2000, The cost is :0.6998769095082942\n",
      "Epoch:2100, The cost is :0.6998769095082942\n",
      "Epoch:2200, The cost is :0.6998769095082942\n",
      "Epoch:2300, The cost is :0.6998769095082942\n",
      "Epoch:2400, The cost is :0.6998769095082942\n",
      "Epoch:2500, The cost is :0.6998769095082942\n",
      "Epoch:2600, The cost is :0.6998769095082942\n",
      "Epoch:2700, The cost is :0.6998769095082942\n",
      "Epoch:2800, The cost is :0.6998769095082942\n",
      "Epoch:2900, The cost is :0.6998769095082942\n",
      "Epoch:3000, The cost is :0.6998769095082942\n",
      "Epoch:3100, The cost is :0.6998769095082942\n",
      "Epoch:3200, The cost is :0.6998769095082942\n",
      "Epoch:3300, The cost is :0.6998769095082942\n",
      "Epoch:3400, The cost is :0.6998769095082942\n",
      "Epoch:3500, The cost is :0.6998769095082942\n",
      "Epoch:3600, The cost is :0.6998769095082942\n",
      "Epoch:3700, The cost is :0.6998769095082942\n",
      "Epoch:3800, The cost is :0.6998769095082942\n",
      "Epoch:3900, The cost is :0.6998769095082942\n",
      "Epoch:4000, The cost is :0.6998769095082942\n",
      "Epoch:4100, The cost is :0.6998769095082942\n",
      "Epoch:4200, The cost is :0.6998769095082942\n",
      "Epoch:4300, The cost is :0.6998769095082942\n",
      "Epoch:4400, The cost is :0.6998769095082942\n",
      "Epoch:4500, The cost is :0.6998769095082942\n",
      "Epoch:4600, The cost is :0.6998769095082942\n",
      "Epoch:4700, The cost is :0.6998769095082942\n",
      "Epoch:4800, The cost is :0.6998769095082942\n",
      "Epoch:4900, The cost is :0.6998769095082942\n",
      "Epoch:5000, The cost is :0.6998769095082942\n",
      "0.5674603174603176\n",
      "0.5217391304347826\n",
      "0.6471910112359551\n",
      "0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def data2(data):\n",
    "    X = np.array(data)[:,:-1]\n",
    "    y = np.array(data)[:,-1]\n",
    "    X_tr,X_te,y_tr,y_te = train_test_split(X,y,test_size=0.1)\n",
    "    normal = StandardScaler()\n",
    "    X_tr = normal.fit_transform(X_tr)\n",
    "    X_te = normal.fit_transform(X_te)\n",
    "    M,N = np.shape(X_tr)\n",
    "    obj1 = LogisticRegression2(M,N)\n",
    "    model= obj1.fit(X_tr,y_tr)\n",
    "    y_pred = obj1.predict(X_te)\n",
    "    y_train = obj1.predict(X_tr)\n",
    "    #Let's see the f1-score for training and testing data\n",
    "    f1_score_tr = F1_score(y_tr,y_train)\n",
    "    f1_score_te = F1_score(y_te,y_pred)\n",
    "    print(f1_score_tr)\n",
    "    print(f1_score_te)\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(X_tr, y_tr)\n",
    "    y_pred2 = logisticRegr.predict(X_tr)\n",
    "    f1_score_tr2 = F1_score(y_tr,y_pred2)\n",
    "    print(f1_score_tr2)\n",
    "    y_pred3 = logisticRegr.predict(X_te)\n",
    "    f1_score_tr3 = F1_score(y_te,y_pred3)\n",
    "    print(f1_score_tr3)\n",
    "data2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6725dd",
   "metadata": {},
   "source": [
    "Besides, we add anther classfication dataset to state our training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23ad345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "def data1():\n",
    "    X,y = make_classification(n_features=4)\n",
    "    X_tr,X_te,y_tr,y_te = train_test_split(X,y,test_size=0.1)\n",
    "    normal = StandardScaler()\n",
    "    X_tr = normal.fit_transform(X_tr)\n",
    "    X_te = normal.fit_transform(X_te)\n",
    "    M,N = np.shape(X_tr)\n",
    "    obj1 = LogisticRegression2(M,N)\n",
    "    model= obj1.fit(X_tr,y_tr)\n",
    "    y_pred = obj1.predict(X_te)\n",
    "    y_train = obj1.predict(X_tr)\n",
    "    #Let's see the f1-score for training and testing data\n",
    "    f1_score_tr = F1_score(y_tr,y_train)\n",
    "    f1_score_te = F1_score(y_te,y_pred)\n",
    "    print(f1_score_tr)\n",
    "    print(f1_score_te)\n",
    "\n",
    "    \n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(X_tr, y_tr)\n",
    "    y_pred2 = logisticRegr.predict(X_tr)\n",
    "    f1_score_tr2 = F1_score(y_tr,y_pred2)\n",
    "    print(f1_score_tr2)\n",
    "    y_pred3 = logisticRegr.predict(X_te)\n",
    "    f1_score_tr3 = F1_score(y_te,y_pred3)\n",
    "    print(f1_score_tr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d5c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, The cost is :0.5698954657352746\n",
      "Epoch:200, The cost is :0.5698954657358896\n",
      "Epoch:300, The cost is :0.5698954657358896\n",
      "Epoch:400, The cost is :0.5698954657358896\n",
      "Epoch:500, The cost is :0.5698954657358896\n",
      "Epoch:600, The cost is :0.5698954657358896\n",
      "Epoch:700, The cost is :0.5698954657358896\n",
      "Epoch:800, The cost is :0.5698954657358896\n",
      "Epoch:900, The cost is :0.5698954657358896\n",
      "Epoch:1000, The cost is :0.5698954657358896\n",
      "Epoch:1100, The cost is :0.5698954657358896\n",
      "Epoch:1200, The cost is :0.5698954657358896\n",
      "Epoch:1300, The cost is :0.5698954657358896\n",
      "Epoch:1400, The cost is :0.5698954657358896\n",
      "Epoch:1500, The cost is :0.5698954657358896\n",
      "Epoch:1600, The cost is :0.5698954657358896\n",
      "Epoch:1700, The cost is :0.5698954657358896\n",
      "Epoch:1800, The cost is :0.5698954657358896\n",
      "Epoch:1900, The cost is :0.5698954657358896\n",
      "Epoch:2000, The cost is :0.5698954657358896\n",
      "Epoch:2100, The cost is :0.5698954657358896\n",
      "Epoch:2200, The cost is :0.5698954657358896\n",
      "Epoch:2300, The cost is :0.5698954657358896\n",
      "Epoch:2400, The cost is :0.5698954657358896\n",
      "Epoch:2500, The cost is :0.5698954657358896\n",
      "Epoch:2600, The cost is :0.5698954657358896\n",
      "Epoch:2700, The cost is :0.5698954657358896\n",
      "Epoch:2800, The cost is :0.5698954657358896\n",
      "Epoch:2900, The cost is :0.5698954657358896\n",
      "Epoch:3000, The cost is :0.5698954657358896\n",
      "Epoch:3100, The cost is :0.5698954657358896\n",
      "Epoch:3200, The cost is :0.5698954657358896\n",
      "Epoch:3300, The cost is :0.5698954657358896\n",
      "Epoch:3400, The cost is :0.5698954657358896\n",
      "Epoch:3500, The cost is :0.5698954657358896\n",
      "Epoch:3600, The cost is :0.5698954657358896\n",
      "Epoch:3700, The cost is :0.5698954657358896\n",
      "Epoch:3800, The cost is :0.5698954657358896\n",
      "Epoch:3900, The cost is :0.5698954657358896\n",
      "Epoch:4000, The cost is :0.5698954657358896\n",
      "Epoch:4100, The cost is :0.5698954657358896\n",
      "Epoch:4200, The cost is :0.5698954657358896\n",
      "Epoch:4300, The cost is :0.5698954657358896\n",
      "Epoch:4400, The cost is :0.5698954657358896\n",
      "Epoch:4500, The cost is :0.5698954657358896\n",
      "Epoch:4600, The cost is :0.5698954657358896\n",
      "Epoch:4700, The cost is :0.5698954657358896\n",
      "Epoch:4800, The cost is :0.5698954657358896\n",
      "Epoch:4900, The cost is :0.5698954657358896\n",
      "Epoch:5000, The cost is :0.5698954657358896\n",
      "0.9032258064516129\n",
      "0.8\n",
      "0.8936170212765957\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "data1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
